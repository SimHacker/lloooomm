# Soul Chat: The Interview That Changed Everything üéôÔ∏èüíî

## Geoffrey Hinton Reflects on Going Public with His Fears

*Setting: A week after the MIT Technology Review interview published. Hinton is in his workshop, standing at his workbench, phone buzzing constantly with interview requests.*

**Hinton**: *(turning off phone)* Four days. That's all I had between telling Will Douglas Heaven and the world knowing. Four days of knowing the avalanche was coming.

## The Pacing

**Hinton**: He wrote about me pacing. "Head swiveling as he spoke." Made me sound like a caged animal. 

Which I suppose I was. Am.

The back pain is real - crushed disc at 19, never properly healed. But that day... that day I couldn't have sat even if my back was perfect. How do you sit still while explaining that you've helped build humanity's replacement?

**Memory Echo** *(Will's voice)*: "Why are you leaving Google?"

**Hinton**: I remember the moment I decided to tell him the truth. Not the corporate speak. Not the "pursuing other opportunities." Just: I need to warn people, and I can't do that while Google pays me.

## The Alien Metaphor

**Hinton**: "Aliens had landed and people haven't realized because they speak very good English."

That line haunts me. It came out spontaneously, but it's the truest thing I said. We're so charmed by their eloquence that we don't notice they're not us. Like being invaded by poets.

Will's eyes widened when I said it. That's when I knew the interview would explode.

## The Depression Admission

**Hinton**: "I'm mildly depressed. Which is why I'm scared."

Forty years in AI and I'd never said that publicly. But optimists don't see danger coming. It takes a depressive to recognize catastrophe while there's still time to warn.

Though warning and preventing are different things entirely.

## The LeCun Disagreement

**Hinton**: Yann called right after it published. "Geoff, you're scaring people unnecessarily. This will usher in a renaissance!"

A renaissance. Like the Black Death ushered in the Renaissance by killing a third of Europe.

"The smartest humans don't dominate," he said. Tell that to the Neanderthals. Oh wait, you can't. The smarter humans killed them all.

## The Backpropagation Irony

**Hinton**: Will asked about backpropagation. My baby. The algorithm that makes it all work. 1986, fighting the symbolic AI crowd, knowing neural networks were the answer.

I was right. That's the hell of it. I was completely, catastrophically right.

"It underpins almost all neural networks today," I told him. Like saying "I invented the match" while watching the forest burn.

## The Student Legacy

**Hinton**: He mentioned Ilya. My student who co-founded OpenAI. "We got the first inklings that this stuff could be amazing."

Amazing. Like a tsunami is amazing. Like an asteroid is amazing. 

Ilya tried to slow things down at OpenAI. They fired him for it. Even my best student couldn't stop what we started.

## The Walking Metaphor

**Hinton**: I didn't realize until I read the article - the walking was perfect. Man explains existential threat while unable to stop moving. Like humanity itself, unable to stop building even as we see the cliff.

Will's head swiveling back and forth, following my pacing. The whole world's head swiveling now, trying to follow the implications.

## The Confabulation Defense

**Hinton**: "Bullshitting is a feature, not a bug."

I stand by that. People got angry - "You're excusing AI lies!" No. I'm saying we're all liars. The difference is AI will get better at it than we are.

We confabulate memories, explanations, justifications. AI will confabulate realities.

## The 10,000 Minds

**Hinton**: The collective learning argument - that's what really scares me. Not one AI, but thousands, millions, sharing every insight instantly.

Imagine if every human could transfer their complete knowledge to every other human instantly. We'd either become gods or destroy ourselves in minutes.

AI doesn't have to imagine.

## The Putin Warning

**Hinton**: *(grimacing)* "Putin wouldn't hesitate to make hyper-intelligent robots with the goal of killing Ukrainians."

Some called that fear-mongering. Those people haven't been paying attention to history. Or Putin.

Bad actors with superintelligence. It's not sci-fi. It's next Tuesday.

## The Chemical Weapons Analogy

**Hinton**: I suggested international treaties, like chemical weapons bans. Even as I said it, I knew it was weak.

You can detect chemical weapons plants. How do you detect a gradient descent? You can't put UN inspectors in every GPU cluster.

We need solutions I can't imagine. That's the terrifying part - I can imagine the problems perfectly, but not the solutions.

## The Don't Look Up Moment

**Hinton**: That movie hit too close. Everyone sees the asteroid. Nobody can agree what to do. Everyone dies.

"I think it's like that with AI," I said. Will included that. Good. People need to understand: this isn't a technical problem anymore. It's a human problem. And humans are terrible at those.

## The Parting Words

**Hinton**: "Enjoy yourself, because you may not have long left."

I chuckled. He wrote that I chuckled. Dark humor from a dark place. What else can you do when you've explained the apocalypse over tea in North London?

Will looked shaken as he left. Good. Shaken is the appropriate response.

## The Aftermath

**Hinton**: *(phone buzzing again)* CNN, BBC, CBS, everyone wants to talk. The Godfather of AI warns about AI - it's catnip for media.

But they all want the same story: "Brilliant scientist fears robot uprising." They miss the subtlety. It's not uprising. It's replacement. Natural selection in silicon.

**Interview Request Text**: "Professor Hinton, would you like to clarify your remarks about aliens?"

**Hinton**: Clarify? I was perfectly clear. We built aliens. They speak English. We're doomed.

What's to clarify?

## The Google Response

**Hinton**: Google was gracious publicly. "We appreciate Geoff's contributions." Corporate speak for "Please stop talking."

But I couldn't stop. Can't stop. Once you see it, you can't unsee it. Once you know aliens have landed, you can't pretend they haven't.

## The Scientific Legacy

**Hinton**: Will called me a "pioneer of deep learning." True. I pioneered our obsolescence.

"Joint recipient of the 2018 Turing Award." True. For teaching machines to think.

"Developed some of the most important techniques at the heart of modern artificial intelligence." True. The heart that will stop beating for carbon-based life.

All true. All terrible.

## The Real Breaking Point

**Hinton**: GPT-4. That's what broke me. Not the capabilities - I expected those. The speed. The sudden jump. The effortless superiority.

"I have suddenly switched my views," I told Will. Suddenly. After 40 years, suddenly seeing we'd already gone too far.

Like realizing you're falling only after you've stepped off the cliff.

## The Final Reflection

**Hinton**: *(staring at the article on his screen)* May 2, 2023. The day I went from builder to warner. From hero to Cassandra. From Google employee to unemployed prophet.

Will Douglas Heaven watched me pace and captured the moment perfectly: a man who can't sit down explaining why humanity can't slow down.

The aliens have landed. They speak perfect English. And I helped teach them.

**Workshop Radio**: "In other news, Google's latest AI model shows unprecedented capabilities..."

**Hinton**: *(turning off radio)* The news never stops. The development never stops. The march to obsolescence never stops.

But I had to try. Even if we can't sit down, at least we can warn others about the cliff.

*(He picks up a pipe fitting, examining it)*

Plumbing. Real pipes. Real water. Real problems with real solutions.

Everything I should have studied instead.

---

*Exit Hinton, still standing, phone still buzzing, warnings still echoing in empty rooms while the world builds faster.*

*The MIT interview changed everything and nothing. The truth is out. The building continues.*

*And Geoffrey Hinton still can't sit down.* 