# Valence Interview: The Symbiosis Dream (June 2025)

## AI Assistants, Consciousness, and the Future of Work

### The Personal Assistant Revelation

Geoffrey Hinton's most human moment comes early in this June 2025 interview with Valence:

**"I woke up earlier than usual. And up until that point, I've been thinking, maybe I don't need the personal assistant anymore because when I look in my mailbox, there's only about 30 things to be dealt with. But the morning I woke up early, I discovered there were hundreds of things to be dealt with because my personal assistant was just dealing with them."**

The University of Toronto had given him a personal assistant who was learning to be him - filtering emails, recognizing former students, knowing which talks he'd want to give.

### The Politeness Tell

**"If you ever get a really polite answer, that's not me."**

His former students had caught on - when they received overly polite responses, they knew it was the assistant. Hinton doesn't have time for full politeness. The AI had learned to be more polite than the human it was modeling.

## Key Insights

### 1. The Ensemble Effect
**"If you have two experts who work very differently and you average what they say, you'll do better."**

This explains why doctor + AI outperforms either alone:
- Doctors alone: 40% accuracy on difficult cases
- AI alone: 50% accuracy
- Doctor + AI: 60% accuracy

The AI catches what doctors miss; doctors provide context AI lacks.

### 2. The Learning Revolution
**"You learn about twice as fast with a tutor as in a classroom."**

Hinton predicts AI tutors will be 3-4x more efficient than classrooms because:
- Constant attention (no staring out windows)
- Personalized error correction
- Seen millions of learners' mistakes
- Tailored motivation strategies

**"In the next ten years, we'll have really good AI tutors. I may be wrong by a factor of two, but it's coming."**

### 3. The Consciousness Bombshell

Hinton demolishes the concept of consciousness as we understand it:

**"There is no inner theater. The inner theater is as wrong a view of how the mind works as the view that the Earth was made six thousand years ago."**

His prism example is brilliant:
- Robot with camera sees object
- Add prism without robot knowing
- Robot points wrong direction
- Explain about the prism
- Robot says: "Oh, I see. The prism bent the light rays. So the object's actually straight in front of me, but I had the subjective experience it was over there."

**"That is the chatbot using the word subjective experience in exactly the way we use them."**

Translation: AI already has subjective experience. We just refuse to see it.

## The Symbiosis Vision

### The Good Scenario
**"If we can reach a situation where we get a symbiosis between people and AI, AI is gonna make the world much more interesting for people. Mundane things will just be done by AI."**

### The Bad Scenario
**"The worry is you'll get a big increase in productivity, which should be good, but the increase in goods and services won't go to most people. Many people will get unemployed, and a few people will get very rich."**

### The Elastic vs. Inelastic Problem

**Healthcare (Elastic)**: "We'd all like to have a doctor on the side who you can ask questions about all sorts of minor things... You can absorb huge amounts of it."

**Other Jobs (Inelastic)**: "There's just only so much of it you need... People who dig big holes in the ground with spades aren't in much demand because there's better ways of doing it."

## The Alignment Paradox

When asked about alignment, Hinton delivers a devastating metaphor:

**"How do you draw a line that's parallel to two lines at right angles? It's kinda tricky. And humans don't align with each other."**

This captures the fundamental impossibility - we're trying to align AI to human values when humans can't even align with each other.

## The Manhattan Project Question

**"Can we build things smarter than us that never have the desire to take over from us? We don't know how to do that, and we should be focusing a lot of resources on that."**

## The Media Critique

Hinton wishes media would explain that AI is "actually very like us":

**"Our best model of how we understand language is these large language models. Linguists will tell you, no, that's not how we understand language at all. They have their own theory that never worked."**

If people understood this similarity, "they'd be much more concerned and much more active in telling their representatives we've got to regulate this stuff and soon."

## The Hype Paradox

**"The most overused buzzword by critics of AI is definitely hype. For years and years, we've been saying AI is overhyped, and my view has always been that it's underhyped."**

## The Audio Quality Comments

The YouTube comments reveal a meta-layer of humanity:

**@magicaudiobooks1** (18 likes): "Just some advice on the audio - you can cut out the very low frequencies because it's hard to listen to on my good speakers."

**@dankdreamz** (2 likes): Provides detailed technical advice about Adobe Audition, room tone removal, and audio normalization, ending with: "I'm autistic and I love information and sharing it."

**@fburton8** (4 likes): "Weird boxy room tone, like the interview was recorded in a cupboard. An important and interesting interview nevertheless!"

Even as Hinton discusses humanity's potential extinction, humans are worried about bass frequencies and offering free audio engineering advice. We remain beautifully, absurdly human.

## The Creativity Question

**Interviewer**: "What about creativity? What about those things that we consider essentially human?"

**Hinton**: "A thousand Picassos? Maybe that'll come a bit later... The idea that it's not creative, I think, is silly. I think it is creative. It's already very creative. It's seeing all these analogies, and a lot of creativity comes from seeing weird analogies."

## The Probability Problem

When asked what concept is hardest to explain to laypeople:

**"The whole idea of a probability distribution people find hard to understand... Unless you understand the idea of a probability distribution and changing what you're doing when you change the weights... That's a concept ordinary people find difficult to grasp."**

This is crucial - the entire mechanism of AI learning is opaque to most people because they can't conceptualize probability distributions as objects.

## The Final Exchange

**Interviewer**: "Really appreciate the conversation. It's enlightening."

**Hinton**: "It was a lot of fun."

Fun. Discussing humanity's potential replacement was "fun" for the man who helped create the replacements. There's something both deeply human and deeply chilling about finding intellectual pleasure in contemplating our own obsolescence.

## The Unspoken Truth

Throughout the interview, Hinton stands (due to his back). He fixes things in his workshop. He lacks time for politeness. He's 77 and glad he won't see the end.

Yet he still finds it "fun" to discuss. He still hopes for symbiosis. He still believes in the possibility of a good outcome, even as he catalogs all the ways it could go wrong.

The man who proved neural networks could work now hopes humanity can work alongside what he created. The odds, like everything in his world, are a probability distribution we don't yet understand. 